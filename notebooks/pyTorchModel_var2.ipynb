{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Component word embeddings\n",
    "\n",
    "class MultiComp(nn.Module):\n",
    "    def __init__(self, word_embeddings_to_comp, n_comp=3):\n",
    "        \"\"\"\n",
    "        word_embeddings_to_comp: word embeddings of the target word;\n",
    "                                 shape = (n_words,100);\n",
    "        \n",
    "        \"\"\"\n",
    "        super(MultiComp, self).__init__()\n",
    "        self.n_comp = n_comp\n",
    "        \n",
    "        n_words, embedding_size = word_embeddings_to_comp.shape\n",
    "        # expand to duplicate embeddings n_comp times\n",
    "        expanded_word_embeddings = np.expand_dims(word_embeddings_to_comp, 1)\n",
    "        comp_embeddings = np.tile(expanded_word_embeddings, [1, n_comp, 1])\n",
    "        \n",
    "        # add some noise to components (1/3 of its standard deviations)\n",
    "        stds = word_embeddings_to_comp.std(axis=1, keepdims=True).reshape([n_words, 1, 1])\n",
    "        comp_embeddings += np.random.randn(n_words, n_comp, embedding_size)  * stds  / 10\n",
    "        comp_embeddings = np.random.randn(n_words, n_comp, embedding_size)  * stds  / 10\n",
    "        comp_embeddings = comp_embeddings.astype(np.float32)\n",
    "        \n",
    "        self.n_centroids = np.random.randn(n_words, n_comp, embedding_size)  * stds  / 10\n",
    "        self.n_centroids = self.n_centroids.astype(np.float32)\n",
    "        \n",
    "        # create variable to use autograd\n",
    "        self.words_comps = nn.Parameter(torch.from_numpy(comp_embeddings))\n",
    "        \n",
    "#         # weight matrices for attention (times 2 because concat context and comp)\n",
    "#         weights = np.random.randn(n_words, embedding_size * 2, 1)\n",
    "#         # xavier\n",
    "#         weights = weights * np.sqrt(2 / (embedding_size + n_comp))\n",
    "#         weights = weights.astype(np.float32)\n",
    "#         self.att_w = nn.Parameter(torch.from_numpy(weights))\n",
    "#         self.att_b = nn.Parameter(torch.zeros(n_words, n_comp, 1))\n",
    "                \n",
    "    def forward(self, context_embeddigs, word_n):\n",
    "        \"\"\"\n",
    "        context_embeddings: shape = (n_context_words, 100);\n",
    "        word_n: number of main_word for what the forward is running;\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # pick word_embeddings and linear layer weights\n",
    "        w_comps = self.words_comps[word_n]\n",
    "#         att_w = self.att_w[word_n]\n",
    "#         att_b = self.att_b[word_n]\n",
    "        # sum the context across words dim \n",
    "        cont_sum = np.mean(context_embeddigs, axis=0)\n",
    "        cont_sum = cont_sum.astype(np.float32)\n",
    "#         print(cont_sum.shape)\n",
    "#         print(self.n_centroids[word_n].shape)\n",
    "#         cont_sum_repeated = cont_sum.repeat(self.n_comp, 1)\n",
    "        scores_tmp = np.matmul(self.n_centroids[word_n], cont_sum)\n",
    "        scores = Variable(torch.from_numpy(scores_tmp))\n",
    "        scores = fn.softmax(scores, 0)\n",
    "        values, indices = scores.max(0)\n",
    "        \n",
    "        for n in range(self.n_comp):\n",
    "            self.n_centroids[word_n][n]+=cont_sum*scores[n].data\n",
    "            self.n_centroids[word_n][n]/=np.sqrt(self.n_centroids[word_n][n]**2)\n",
    "        \n",
    "#         self.n_centroids[word_n][indices.data]+=cont_sum\n",
    "#         self.n_centroids[word_n][indices.data]/=np.sqrt(self.n_centroids[word_n][indices.data]**2)\n",
    "            \n",
    "#         print(scores)\n",
    "#         print(values, indices)\n",
    "\n",
    "#         att_input = torch.cat([cont_sum_repeated, w_comps], dim=1)\n",
    "#         att = torch.matmul(att_input, att_w) + att_b\n",
    "#         att = fn.softmax(att, 0)\n",
    "#         comps_sum = torch.sum(w_comps * scores.expand_as(w_comps), 0)\n",
    "        comps_sum = torch.matmul(scores, w_comps)\n",
    "        cont_sum = Variable(torch.from_numpy(cont_sum))\n",
    "        dot_prod = torch.matmul(comps_sum, cont_sum.squeeze())/(torch.norm(comps_sum, p=1) * torch.norm(cont_sum, p=1))\n",
    "#         print(dot_prod)\n",
    "        #         dot_prod = fn.cosine_embedding_loss(w_comps[indices.data].double(), cont_sum.squeeze(), 1, 0, True)\n",
    "        return dot_prod, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.n_centroids[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.8303\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.2837\n",
      " 0.3223\n",
      " 0.3940\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -1.2066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0018\n",
      " 0.8423\n",
      " 0.1559\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  2.8472\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0260\n",
      " 0.8805\n",
      " 0.0936\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  3.2664\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.9533\n",
      " 0.0415\n",
      " 0.0052\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  9.9802\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.6413\n",
      " 0.0459\n",
      " 0.3128\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  9.9665\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.1220\n",
      " 0.8632\n",
      " 0.0148\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  2.1980\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.7519\n",
      " 0.2031\n",
      " 0.0450\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      " -9.0106\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.5775\n",
      " 0.4015\n",
      " 0.0210\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      " -2.2135\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.2146\n",
      " 0.1738\n",
      " 0.6116\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  3.2357\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0048\n",
      " 0.9124\n",
      " 0.0828\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -1.2101\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.9623\n",
      " 0.0191\n",
      " 0.0186\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.1309\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0997\n",
      " 0.4902\n",
      " 0.4101\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  3.7814\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.5292\n",
      " 0.1680\n",
      " 0.3029\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-05 *\n",
      " -9.2691\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.7511\n",
      " 0.0119\n",
      " 0.2370\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      " -2.8381\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0516\n",
      " 0.1358\n",
      " 0.8126\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -1.6217\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.2750\n",
      " 0.0533\n",
      " 0.6717\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  2.7192\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.7435\n",
      " 0.2518\n",
      " 0.0047\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.6999\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.5423\n",
      " 0.0468\n",
      " 0.4109\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  1.6971\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0781\n",
      " 0.5841\n",
      " 0.3378\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.5157\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0096\n",
      " 0.9617\n",
      " 0.0287\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      " -7.5825\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.1197\n",
      " 0.8647\n",
      " 0.0156\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  7.8233\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.5225\n",
      " 0.4506\n",
      " 0.0269\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      " -1.7007\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.1873\n",
      " 0.0162\n",
      " 0.7964\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.6598\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0074\n",
      " 0.9677\n",
      " 0.0249\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -1.3271\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0958\n",
      " 0.0520\n",
      " 0.8521\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      " -1.4181\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0192\n",
      " 0.0062\n",
      " 0.9746\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      " -1.5212\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.8950\n",
      " 0.0033\n",
      " 0.1017\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -1.3001\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.9068\n",
      " 0.0042\n",
      " 0.0890\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -1.2811\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0459\n",
      " 0.2110\n",
      " 0.7431\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  2.7237\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.9261\n",
      " 0.0246\n",
      " 0.0494\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -1.1832\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.1199\n",
      " 0.7279\n",
      " 0.1522\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      " -8.0642\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.1292\n",
      " 0.8283\n",
      " 0.0425\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  7.2357\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.2869\n",
      " 0.7125\n",
      " 0.0006\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -2.4631\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0823\n",
      " 0.6833\n",
      " 0.2345\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  2.7229\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.9969\n",
      " 0.0029\n",
      " 0.0002\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  9.8777\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.1700\n",
      " 0.0131\n",
      " 0.8169\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  2.7257\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.8294\n",
      " 0.1297\n",
      " 0.0409\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-05 *\n",
      " -1.3835\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0231\n",
      " 0.6814\n",
      " 0.2955\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.4915\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0266\n",
      " 0.8815\n",
      " 0.0919\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  8.9487\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.9885\n",
      " 0.0112\n",
      " 0.0002\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      " -4.1626\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.9870\n",
      " 0.0014\n",
      " 0.0115\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.3330\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0450\n",
      " 0.7239\n",
      " 0.2310\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  1.4030\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0602\n",
      " 0.6134\n",
      " 0.3264\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.5573\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.3101\n",
      " 0.0111\n",
      " 0.6788\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -1.0913\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0126\n",
      " 0.9835\n",
      " 0.0039\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  2.3276\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.8388\n",
      " 0.0336\n",
      " 0.1276\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  4.9249\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0003\n",
      " 0.4005\n",
      " 0.5992\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      " -3.5987\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0215\n",
      " 0.3122\n",
      " 0.6663\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      " -5.9725\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.6207\n",
      " 0.0461\n",
      " 0.3332\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      " -8.8778\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.5927\n",
      " 0.0553\n",
      " 0.3520\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  9.0845\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.7004\n",
      " 0.0262\n",
      " 0.2734\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -1.0504\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.8446\n",
      " 0.1404\n",
      " 0.0150\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  8.2959\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.7113\n",
      " 0.2359\n",
      " 0.0528\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  7.4249\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.9562\n",
      " 0.0235\n",
      " 0.0204\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.1386\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.3150\n",
      " 0.0940\n",
      " 0.5910\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  3.1638\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.9017\n",
      " 0.0472\n",
      " 0.0511\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -1.4814\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0082\n",
      " 0.9567\n",
      " 0.0351\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  7.7090\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.6727\n",
      " 0.1713\n",
      " 0.1560\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.1684\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.7981\n",
      " 0.0903\n",
      " 0.1116\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  2.3856\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.9219\n",
      " 0.0366\n",
      " 0.0415\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  2.6781\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.7125\n",
      " 0.0393\n",
      " 0.2482\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  1.3710\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0285\n",
      " 0.8161\n",
      " 0.1554\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.9385\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0548\n",
      " 0.5910\n",
      " 0.3542\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  9.2401\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.2444\n",
      " 0.5046\n",
      " 0.2510\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  9.5315\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0380\n",
      " 0.0640\n",
      " 0.8980\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      " -7.8607\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0071\n",
      " 0.9644\n",
      " 0.0285\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  2.2236\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.3563\n",
      " 0.0217\n",
      " 0.6219\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  2.7862\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.9041\n",
      " 0.0021\n",
      " 0.0938\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      " -3.0599\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.3111\n",
      " 0.6737\n",
      " 0.0152\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -1.7330\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0064\n",
      " 0.0720\n",
      " 0.9217\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-05 *\n",
      "  7.9110\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0031\n",
      " 0.9962\n",
      " 0.0007\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  1.1339\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0686\n",
      " 0.5507\n",
      " 0.3806\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  1.6116\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.3053\n",
      " 0.3455\n",
      " 0.3492\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -1.0236\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0748\n",
      " 0.2809\n",
      " 0.6443\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  2.7236\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.2650\n",
      " 0.6042\n",
      " 0.1307\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      " -8.4709\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.2476\n",
      " 0.2886\n",
      " 0.4638\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  2.2583\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0400\n",
      " 0.8012\n",
      " 0.1587\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  2.2041\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.1462\n",
      " 0.7638\n",
      " 0.0900\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      " -5.7173\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.8389\n",
      " 0.1479\n",
      " 0.0132\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.5547\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0624\n",
      " 0.2432\n",
      " 0.6944\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  4.0254\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.2187\n",
      " 0.6680\n",
      " 0.1133\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.2822\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.9254\n",
      " 0.0097\n",
      " 0.0649\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  7.7232\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.2812\n",
      " 0.0203\n",
      " 0.6985\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  4.9451\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.6699\n",
      " 0.3066\n",
      " 0.0235\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      " -3.6094\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0123\n",
      " 0.3064\n",
      " 0.6813\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  2.2586\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0979\n",
      " 0.3317\n",
      " 0.5703\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  2.6587\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.1595\n",
      " 0.3861\n",
      " 0.4544\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  5.6023\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.1649\n",
      " 0.8313\n",
      " 0.0038\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -3.3766\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0962\n",
      " 0.8863\n",
      " 0.0175\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -1.6332\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.8842\n",
      " 0.0520\n",
      " 0.0638\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  7.7912\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.4912\n",
      " 0.4922\n",
      " 0.0166\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.1129\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0046\n",
      " 0.0097\n",
      " 0.9857\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -1.0877\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.9716\n",
      " 0.0193\n",
      " 0.0091\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.1434\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0020\n",
      " 0.0015\n",
      " 0.9965\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -2.2913\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.0851\n",
      " 0.0303\n",
      " 0.8846\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -1.7703\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.8048\n",
      " 0.1492\n",
      " 0.0460\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -2.3104\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.9172\n",
      " 0.0780\n",
      " 0.0048\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  2.5290\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.1222\n",
      " 0.8577\n",
      " 0.0201\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      " -1.4378\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.9889\n",
      " 0.0057\n",
      " 0.0054\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  6.4351\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "attn:  Variable containing:\n",
      " 0.1243\n",
      " 0.7230\n",
      " 0.1527\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w_emb = np.random.randn(3, 100)\n",
    "net = MultiComp(w_emb)\n",
    "opt = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "n_samples = 100\n",
    "n_context = 20 # number of words in the context\n",
    "emb_dim = 100\n",
    "for sample in np.random.randn(n_samples, n_context, emb_dim):\n",
    "    # Prepare sample with Variable wrap\n",
    "#     sample = Variable(torch.from_numpy(sample.astype(np.float32)))\n",
    "    net.zero_grad()\n",
    "    dot_prod, att = net.forward(sample, 0)\n",
    "    loss = dot_prod\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    print(loss)\n",
    "    print(\"attn: \", att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 13G\r\n",
      "-rw-r--r-- 1 fogside fogside  8,1G янв 21 18:08 \u001b[0m\u001b[00mbig_one_file.txt\u001b[0m\r\n",
      "-rw-r--r-- 1 fogside fogside   40M янв 21 18:22 \u001b[00mdict.txt\u001b[0m\r\n",
      "drwxr-xr-x 3 fogside fogside  4,0K янв 21 18:05 \u001b[01;34mlibru\u001b[0m/\r\n",
      "-rw-r--r-- 1 fogside fogside  3,0M янв 17 17:42 \u001b[00mmain_contexts_and_test.txt\u001b[0m\r\n",
      "-rw-r--r-- 1 fogside fogside  623M янв 17 17:43 \u001b[00mmain_wiki_and_contexts.txt\u001b[0m\r\n",
      "-rw-r--r-- 1 fogside fogside  620M янв 14 19:34 \u001b[00mmain_words_wiki_normalized_no_punct.txt\u001b[0m\r\n",
      "-rw-r--r-- 1 fogside fogside  732M янв 14 18:56 \u001b[00mmain_words_wiki.txt\u001b[0m\r\n",
      "-rw-r--r-- 1 fogside fogside 1019M окт 20 00:10 \u001b[00mruwiki_00.txt\u001b[0m\r\n",
      "-rw-r--r-- 1 fogside fogside  1,1G янв 13 15:06 \u001b[00mruwiki_tokenized.txt\u001b[0m\r\n",
      "drwxrwxr-x 4 fogside fogside  4,0K янв 19 18:03 \u001b[01;34mНКРЯ\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh ../data/my_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3,0G\r\n",
      "-rw-r--r-- 1 fogside fogside 1,3G дек  8 17:42 \u001b[0m\u001b[00mfast_text_model.bin\u001b[0m\r\n",
      "-rw-r--r-- 1 fogside fogside 587M дек  8 17:42 \u001b[00mfast_text_model.vec\u001b[0m\r\n",
      "-rw-r--r-- 1 fogside fogside 923M янв 22 04:51 \u001b[00mmodel_big_one.bin\u001b[0m\r\n",
      "-rw-r--r-- 1 fogside fogside 171M янв 22 04:51 \u001b[00mmodel_big_one.vec\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh ../models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "stemmer = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_indexes(lst, word):\n",
    "    res = []\n",
    "    i = 0\n",
    "    while(True):\n",
    "        try:\n",
    "            i = lst.index(word, i)\n",
    "            res.append(i)\n",
    "            i+=1\n",
    "        except:\n",
    "            break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(word, window):\n",
    "    N = 1669868\n",
    "    w = stemmer.lemmatize(word)[0]\n",
    "    counter = 0\n",
    "\n",
    "    with open(\"../data/my_data/big_one_file.txt\", 'r') as bigf,\\\n",
    "    open(\"../data/my_data/{}_out.txt\".format(word), 'a') as fout:\n",
    "        for i in tqdm_notebook(range(N)):\n",
    "            line = bigf.readline().split()\n",
    "            if w in line:\n",
    "                idxs = get_all_indexes(line, w)\n",
    "                for i in idxs:\n",
    "                    counter+=1\n",
    "                    # each line is a group of neighbour words with length = 3*window\n",
    "                    start = max(0, i-1-window) # if 0 is max then all before main word will be selected\n",
    "                    fout.write(\" \".join(line[start:i-1])+\" \"+\" \".join(line[i:i+window])+'\\n')\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1669868/1669868 [01:11<00:00, 23263.62it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "111462"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dataset(word='замок', window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "wv = KeyedVectors.load_word2vec_format(\"../models/model_big_one.vec\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/my_data/{}_out.txt\".format('замок'), 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(lines, context_max_len):\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        embedd = []\n",
    "        for i, w in enumerate(line[:context_max_len]):\n",
    "            try:\n",
    "                embedd.append(wv[w])\n",
    "            except KeyError:\n",
    "                continue\n",
    "        yield np.array(embedd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11539709c37e4edbb33b54c58f945d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=111462), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num:  0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/fogside/virtualenvs/py3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/fogside/virtualenvs/py3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859c47f725064d06b07a2cbc56e8f82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=111462), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num:  1\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1b1eaf626e41eb80174107b600739d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=111462), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num:  2\n"
     ]
    }
   ],
   "source": [
    "w_emb = wv['замок'].reshape((1,100))\n",
    "net = MultiComp(w_emb, 3)\n",
    "opt = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "n_samples = len(lines)\n",
    "n_context = 20 # number of words in the context\n",
    "emb_dim = 100\n",
    "atts = list()\n",
    "epoch_num = 3\n",
    "for epoch in range(epoch_num):\n",
    "    batch_gen = generate_batch(lines, context_max_len=20)\n",
    "    pbar = tqdm_notebook(batch_gen, total = n_samples)\n",
    "    print(\"epoch_num: \", epoch)\n",
    "    for n, sample in enumerate(pbar):\n",
    "        # Prepare sample with Variable wrap\n",
    "    #     sample = Variable(torch.from_numpy(sample.astype(np.float32)))\n",
    "        net.zero_grad()\n",
    "        dot_prod, att = net.forward(sample, 0)\n",
    "        atts.append(att.data.numpy())\n",
    "        loss = -dot_prod \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if n % 100 == 99:\n",
    "            pbar.set_description(\"loss {:.3f}\".format(float(loss.data.numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad is\n",
      "[[[-3.49486129e-07 -3.32365261e-07  7.03760350e-07 -2.97755946e-07\n",
      "    3.56533036e-07 -5.35514573e-07 -1.10389169e-06 -4.66065700e-07\n",
      "   -5.82917210e-07 -7.27230713e-07 -2.60619970e-07  8.72017154e-07\n",
      "   -8.08192112e-07 -1.07066981e-07 -1.75066830e-07 -6.79283175e-07\n",
      "   -9.17846492e-08  1.09717249e-07 -8.09712787e-07 -2.83074058e-07\n",
      "   -1.10584521e-10 -3.18478584e-07  1.89186693e-07 -7.15673593e-07\n",
      "   -6.53958921e-07 -4.84765849e-07  5.89442948e-07  4.24560113e-07\n",
      "    6.29939223e-07  1.76845361e-07 -1.02231468e-06  4.03644037e-07\n",
      "   -4.14105955e-07 -6.08837638e-07 -8.30337115e-07  2.56671797e-07\n",
      "    4.60513974e-07 -4.49053999e-07  9.50191861e-07 -3.75076752e-07\n",
      "    1.45197220e-07 -7.48199170e-07 -4.16173862e-07 -8.43637110e-07\n",
      "   -7.23692779e-07 -6.04928402e-07  6.47262880e-07 -5.54983956e-07\n",
      "    9.16100305e-07 -8.20186301e-07  1.35696598e-06  3.22151266e-07\n",
      "   -2.76605135e-07 -8.56098382e-07  1.24399762e-07  5.11047290e-07\n",
      "   -4.81783104e-07 -1.36427346e-07 -3.60368801e-07  6.78010622e-07\n",
      "   -6.71486362e-07  3.75097272e-07  7.24174640e-07  3.85649855e-07\n",
      "    9.03209639e-07 -8.27155134e-07  4.29205443e-07 -4.94950655e-07\n",
      "   -8.23087476e-07 -6.44780073e-07 -3.46378300e-07 -8.53632741e-07\n",
      "   -6.87931788e-07  5.99375824e-07  3.05084626e-07 -5.00501244e-07\n",
      "    5.49716901e-07  7.74767670e-07 -5.25372172e-07 -8.34696266e-07\n",
      "    4.02859257e-07 -5.88054945e-07 -2.34320169e-07 -5.57311182e-07\n",
      "    3.96894734e-07 -6.31295194e-08 -6.73349973e-07  6.82466180e-07\n",
      "   -3.06065999e-07 -5.78926688e-07  7.64207073e-07  6.21473475e-07\n",
      "    7.68467771e-07  5.65165237e-07 -2.26010130e-07 -4.38151204e-07\n",
      "   -9.56584017e-07  7.43772205e-07  4.64715981e-07 -2.42843214e-07]\n",
      "  [-1.60727231e-03 -1.52853411e-03  3.23656481e-03 -1.36936724e-03\n",
      "    1.63968070e-03 -2.46280944e-03 -5.07675251e-03 -2.14341702e-03\n",
      "   -2.68081203e-03 -3.34450416e-03 -1.19858049e-03  4.01037093e-03\n",
      "   -3.71684227e-03 -4.92396590e-04 -8.05125106e-04 -3.12399538e-03\n",
      "   -4.22113808e-04  5.04585099e-04 -3.72383581e-03 -1.30184588e-03\n",
      "   -5.08573635e-07 -1.46466983e-03  8.70061805e-04 -3.29135312e-03\n",
      "   -3.00753023e-03 -2.22941791e-03  2.71082390e-03  1.95253443e-03\n",
      "    2.89706443e-03  8.13304505e-04 -4.70158318e-03  1.85634219e-03\n",
      "   -1.90445618e-03 -2.80001923e-03 -3.81868612e-03  1.18042296e-03\n",
      "    2.11788458e-03 -2.06518080e-03  4.36989311e-03 -1.72496249e-03\n",
      "    6.67756016e-04 -3.44093703e-03 -1.91396638e-03 -3.87985236e-03\n",
      "   -3.32823326e-03 -2.78204074e-03  2.97673536e-03 -2.55234819e-03\n",
      "    4.21310775e-03 -3.77200288e-03  6.24063099e-03  1.48156041e-03\n",
      "   -1.27209560e-03 -3.93716106e-03  5.72109362e-04  2.35028542e-03\n",
      "   -2.21570069e-03 -6.27423753e-04 -1.65732123e-03  3.11814295e-03\n",
      "   -3.08813807e-03  1.72505691e-03  3.33044934e-03  1.77358766e-03\n",
      "    4.15382395e-03 -3.80405248e-03  1.97389815e-03 -2.27625761e-03\n",
      "   -3.78534524e-03 -2.96531687e-03 -1.59297953e-03 -3.92582174e-03\n",
      "   -3.16376984e-03  2.75650457e-03  1.40307168e-03 -2.30178447e-03\n",
      "    2.52812542e-03  3.56312469e-03 -2.41616485e-03 -3.83873377e-03\n",
      "    1.85273308e-03 -2.70444062e-03 -1.07762881e-03 -2.56305118e-03\n",
      "    1.82530249e-03 -2.90330034e-04 -3.09670880e-03  3.13863368e-03\n",
      "   -1.40758487e-03 -2.66246009e-03  3.51455691e-03  2.85813073e-03\n",
      "    3.53415147e-03  2.59917160e-03 -1.03941129e-03 -2.01503932e-03\n",
      "   -4.39929031e-03  3.42057762e-03  2.13720952e-03 -1.11682585e-03]\n",
      "  [-1.48769195e-05 -1.41481187e-05  2.99576586e-05 -1.26748700e-05\n",
      "    1.51768927e-05 -2.27957771e-05 -4.69904444e-05 -1.98394773e-05\n",
      "   -2.48136093e-05 -3.09567477e-05 -1.10940673e-05  3.71200113e-05\n",
      "   -3.44031105e-05 -4.55762529e-06 -7.45224224e-06 -2.89157160e-05\n",
      "   -3.90708738e-06  4.67044219e-06 -3.44678410e-05 -1.20498917e-05\n",
      "   -4.70736028e-09 -1.35569908e-05  8.05329637e-06 -3.04647820e-05\n",
      "   -2.78377138e-05 -2.06355035e-05  2.50913999e-05  1.80726674e-05\n",
      "    2.68152435e-05  7.52795040e-06 -4.35178772e-05  1.71823121e-05\n",
      "   -1.76276553e-05 -2.59169919e-05 -3.53457763e-05  1.09260009e-05\n",
      "    1.96031506e-05 -1.91153231e-05  4.04477505e-05 -1.59662613e-05\n",
      "    6.18075319e-06 -3.18493294e-05 -1.77156817e-05 -3.59119331e-05\n",
      "   -3.08061426e-05 -2.57505835e-05  2.75526763e-05 -2.36245469e-05\n",
      "    3.89965426e-05 -3.49136753e-05  5.77633073e-05  1.37133302e-05\n",
      "   -1.17745230e-05 -3.64423831e-05  5.29544695e-06  2.17542529e-05\n",
      "   -2.05085362e-05 -5.80743699e-06 -1.53401725e-05  2.88615465e-05\n",
      "   -2.85838214e-05  1.59671345e-05  3.08266535e-05  1.64163357e-05\n",
      "    3.84478117e-05 -3.52103270e-05  1.82704116e-05 -2.10690505e-05\n",
      "   -3.50371738e-05 -2.74469876e-05 -1.47446262e-05 -3.63374238e-05\n",
      "   -2.92838704e-05  2.55142204e-05  1.29868376e-05 -2.13053281e-05\n",
      "    2.34003401e-05  3.29802970e-05 -2.23640345e-05 -3.55313387e-05\n",
      "    1.71489064e-05 -2.50323155e-05 -9.97453753e-06 -2.37236127e-05\n",
      "    1.68950082e-05 -2.68729627e-06 -2.86631512e-05  2.90512089e-05\n",
      "   -1.30286126e-05 -2.46437430e-05  3.25307556e-05  2.64548726e-05\n",
      "    3.27121234e-05  2.40579448e-05 -9.62079594e-06 -1.86512134e-05\n",
      "   -4.07198531e-05  3.16608857e-05  1.97820227e-05 -1.03373459e-05]]]\n"
     ]
    }
   ],
   "source": [
    "for f in net.parameters():\n",
    "#     print('data is')\n",
    "#     print(f.data)\n",
    "    print('grad is')\n",
    "    print(f.grad.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "atts = np.array(atts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.2929372e-01, 4.3153498e-01, 3.3917129e-01],\n",
       "       [1.2789839e-03, 9.7458726e-01, 2.4133760e-02],\n",
       "       [8.6986611e-04, 9.7325903e-01, 2.5871109e-02],\n",
       "       [1.2564140e-03, 9.4226527e-01, 5.6478307e-02],\n",
       "       [1.8663254e-03, 9.5647675e-01, 4.1656919e-02],\n",
       "       [9.5462325e-05, 9.7865313e-01, 2.1251412e-02],\n",
       "       [8.5233944e-04, 9.6639657e-01, 3.2751065e-02],\n",
       "       [4.7745951e-04, 9.5825988e-01, 4.1262675e-02],\n",
       "       [4.7086633e-04, 9.5452482e-01, 4.5004334e-02],\n",
       "       [8.8591996e-04, 9.5081198e-01, 4.8302125e-02],\n",
       "       [4.3654311e-04, 9.7933054e-01, 2.0232894e-02],\n",
       "       [1.1286370e-03, 9.7844708e-01, 2.0424303e-02],\n",
       "       [1.2178138e-03, 9.4687504e-01, 5.1907163e-02],\n",
       "       [1.1501533e-03, 9.8326588e-01, 1.5583949e-02],\n",
       "       [5.2133296e-04, 9.8449069e-01, 1.4987965e-02],\n",
       "       [1.9799334e-04, 9.6790385e-01, 3.1898163e-02],\n",
       "       [8.5847487e-04, 9.8333067e-01, 1.5810886e-02],\n",
       "       [2.6864768e-03, 9.5997661e-01, 3.7336886e-02],\n",
       "       [2.6363318e-04, 9.8203272e-01, 1.7703649e-02],\n",
       "       [2.8834111e-04, 9.7280204e-01, 2.6909588e-02]], dtype=float32)"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atts[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ослица', 0.5227832794189453),\n",
       " ('ниневия', 0.509689211845398),\n",
       " ('калант', 0.505122721195221),\n",
       " ('телец', 0.5043264627456665),\n",
       " ('невероятие', 0.4914008677005768),\n",
       " ('слоновник', 0.488711953163147),\n",
       " ('невон', 0.48820817470550537),\n",
       " ('горошина', 0.4879819452762604),\n",
       " ('савский', 0.48740366101264954),\n",
       " ('одногорбый', 0.48712512850761414),\n",
       " ('невероятно', 0.48405176401138306),\n",
       " ('бегемотовый', 0.4807841181755066),\n",
       " ('порфировый', 0.48065459728240967),\n",
       " ('минерал', 0.4805746078491211),\n",
       " ('безобразный', 0.48055922985076904),\n",
       " ('слон', 0.4802359938621521),\n",
       " ('орода', 0.47562527656555176),\n",
       " ('дромадер', 0.47427913546562195),\n",
       " ('крокодиль', 0.47348499298095703),\n",
       " ('бороздчатый', 0.47335511445999146),\n",
       " ('мира', 0.47249507904052734),\n",
       " ('нанда', 0.47133535146713257),\n",
       " ('гладенький', 0.46967971324920654),\n",
       " ('слизень', 0.4691134989261627),\n",
       " ('подий', 0.46752920746803284),\n",
       " ('пластрон', 0.46675676107406616),\n",
       " ('грушевидный', 0.466746985912323),\n",
       " ('монструозный', 0.4666191637516022),\n",
       " ('ниневий', 0.4665229022502899),\n",
       " ('черний', 0.466391384601593)]"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_vector(net.n_centroids[0][2], 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('либуша', 0.49343714118003845),\n",
       " ('мечькин', 0.49061936140060425),\n",
       " ('альхен', 0.4888174533843994),\n",
       " ('бонтон', 0.4863034784793854),\n",
       " ('тришатов', 0.48624271154403687),\n",
       " ('бертольди', 0.48591262102127075),\n",
       " ('маллинер', 0.48258763551712036),\n",
       " ('полчасика', 0.48102128505706787),\n",
       " ('часок', 0.4807071089744568),\n",
       " ('еспер', 0.47727519273757935),\n",
       " ('зеленуда', 0.4760782718658447),\n",
       " ('часик', 0.4747023284435272),\n",
       " ('мамзель', 0.47147342562675476),\n",
       " ('марихен', 0.4693729281425476),\n",
       " ('алексевна', 0.4686300456523895),\n",
       " ('польди', 0.4684569835662842),\n",
       " ('даровщинка', 0.4683907628059387),\n",
       " ('пользительно', 0.4682873785495758),\n",
       " ('пересаливать', 0.46739619970321655),\n",
       " ('пунтило', 0.466889351606369),\n",
       " ('крыжовенный', 0.4637065529823303),\n",
       " ('мараскин', 0.46335655450820923),\n",
       " ('максинька', 0.4618507921695709),\n",
       " ('фреди', 0.4617885649204254),\n",
       " ('дюбона', 0.46126455068588257),\n",
       " ('ленивица', 0.45895352959632874),\n",
       " ('подразнить', 0.4586748480796814),\n",
       " ('покушать', 0.45825403928756714),\n",
       " ('вотренный', 0.45821258425712585),\n",
       " ('полпорции', 0.4577726721763611)]"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_vector(net.words_comps[0].data.numpy()[0], 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
