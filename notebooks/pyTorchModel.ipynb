{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Component word embeddings\n",
    "\n",
    "class MultiComp(nn.Module):\n",
    "    def __init__(self, word_embeddings_to_comp, n_comp=3):\n",
    "        super(MultiComp, self).__init__()\n",
    "        self.n_comp = n_comp\n",
    "        n_words, embedding_size = word_embeddings_to_comp.shape\n",
    "        # expand to duplicate embeddings n_comp times\n",
    "        expanded_word_embeddings = np.expand_dims(word_embeddings_to_comp, 1)\n",
    "        comp_embeddings = np.tile(expanded_word_embeddings, [1, n_comp, 1])\n",
    "        \n",
    "        # add some noise to components (1/3 of its standard deviations)\n",
    "        stds = word_embeddings_to_comp.std(axis=1, keepdims=True).reshape([n_words, 1, 1])\n",
    "        comp_embeddings += np.random.randn(n_words, n_comp, embedding_size)  * stds  / 3\n",
    "        comp_embeddings = comp_embeddings.astype(np.float32)\n",
    "        \n",
    "        # create variable to use autograd\n",
    "        self.words_comps = nn.Parameter(torch.from_numpy(comp_embeddings))\n",
    "        \n",
    "        # weight matrices for attention (times 2 because concat context and comp)\n",
    "        weights = np.random.randn(n_words, embedding_size * 2, 1)\n",
    "        # xavier\n",
    "        weights = weights * np.sqrt(2 / (embedding_size + n_comp))\n",
    "        weights = weights.astype(np.float32)\n",
    "        self.att_w = nn.Parameter(torch.from_numpy(weights))\n",
    "        self.att_b = nn.Parameter(torch.zeros(n_words, n_comp, 1))\n",
    "                \n",
    "    def forward(self, context_embeddigs, word_n):\n",
    "        # pick word_embeddings and linear layer weigts\n",
    "        w_comps = self.words_comps[word_n]\n",
    "        att_w = self.att_w[word_n]\n",
    "        att_b = self.att_b[word_n]\n",
    "        # sum the context across words dim \n",
    "        cont_sum = torch.mean(context_embeddigs, 0, keepdim=True)\n",
    "        cont_sum_repeated = cont_sum.repeat(self.n_comp, 1)\n",
    "        att_input = torch.cat([cont_sum_repeated, w_comps], dim=1)\n",
    "        att = torch.matmul(att_input, att_w) + att_b\n",
    "        comps_sum = torch.sum(w_comps * att, 0)\n",
    "        dot_prod = torch.matmul(comps_sum, cont_sum.squeeze())\n",
    "        return dot_prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.8111\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "-9.0926\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 10.3019\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 23.8313\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "-1.6813\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 33.3113\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 17.5252\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "-11.2283\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 20.7560\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "-19.4437\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w_emb = np.random.randn(3, 100)\n",
    "net = MultiComp(w_emb)\n",
    "opt = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "n_samples = 10\n",
    "n_context = 20 # number of words in the context\n",
    "emb_dim = 100\n",
    "for sample in np.random.randn(n_samples, n_context, emb_dim):\n",
    "    # Prepare sample with Variable wrap\n",
    "    sample = Variable(torch.from_numpy(sample.astype(np.float32)))\n",
    "    net.zero_grad()\n",
    "    dot_prod = net.forward(sample, 0)\n",
    "    loss = -dot_prod\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 13G\r\n",
      "-rw-r--r-- 1 fogside fogside  8,1G янв 21 18:08 \u001b[0m\u001b[00mbig_one_file.txt\u001b[0m\r\n",
      "-rw-r--r-- 1 fogside fogside   40M янв 21 18:22 \u001b[00mdict.txt\u001b[0m\r\n",
      "drwxr-xr-x 3 fogside fogside  4,0K янв 21 18:05 \u001b[01;34mlibru\u001b[0m/\r\n",
      "-rw-r--r-- 1 fogside fogside  3,0M янв 17 17:42 \u001b[00mmain_contexts_and_test.txt\u001b[0m\r\n",
      "-rw-r--r-- 1 fogside fogside  623M янв 17 17:43 \u001b[00mmain_wiki_and_contexts.txt\u001b[0m\r\n",
      "-rw-r--r-- 1 fogside fogside  620M янв 14 19:34 \u001b[00mmain_words_wiki_normalized_no_punct.txt\u001b[0m\r\n",
      "-rw-r--r-- 1 fogside fogside  732M янв 14 18:56 \u001b[00mmain_words_wiki.txt\u001b[0m\r\n",
      "-rw-r--r-- 1 fogside fogside 1019M окт 20 00:10 \u001b[00mruwiki_00.txt\u001b[0m\r\n",
      "-rw-r--r-- 1 fogside fogside  1,1G янв 13 15:06 \u001b[00mruwiki_tokenized.txt\u001b[0m\r\n",
      "drwxrwxr-x 4 fogside fogside  4,0K янв 19 18:03 \u001b[01;34mНКРЯ\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh ../data/my_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3,0G\r\n",
      "-rw-r--r-- 1 fogside fogside 1,3G дек  8 17:42 \u001b[0m\u001b[00mfast_text_model.bin\u001b[0m\r\n",
      "-rw-r--r-- 1 fogside fogside 587M дек  8 17:42 \u001b[00mfast_text_model.vec\u001b[0m\r\n",
      "-rw-r--r-- 1 fogside fogside 923M янв 22 04:51 \u001b[00mmodel_big_one.bin\u001b[0m\r\n",
      "-rw-r--r-- 1 fogside fogside 171M янв 22 04:51 \u001b[00mmodel_big_one.vec\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh ../models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'замок'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "stemmer = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_indexes(lst, word):\n",
    "    res = []\n",
    "    i = 0\n",
    "    while(True):\n",
    "        try:\n",
    "            i = lst.index(word, i)\n",
    "            res.append(i)\n",
    "            i+=1\n",
    "        except:\n",
    "            break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(word, window):\n",
    "    N = 1669868\n",
    "    w = stemmer.lemmatize(word)[0]\n",
    "    counter = 0\n",
    "\n",
    "    with open(\"../data/my_data/big_one_file.txt\", 'r') as bigf,\\\n",
    "    open(\"../data/my_data/{}_out.txt\".format(word), 'a') as fout:\n",
    "        for i in tqdm(range(N)):\n",
    "            line = bigf.readline().split()\n",
    "            if w in line:\n",
    "                counter+=1\n",
    "                idxs = get_all_indexes(line, w)\n",
    "                fout.write(\"> \"+\" \".join([str(i) for i in idxs])+'\\n')\n",
    "                for i in idxs:\n",
    "                    fout.write(\" \".join(line[])+'\\n')\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1669868/1669868 [01:34<00:00, 17613.25it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17379"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dataset(word='замок')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "wv = KeyedVectors.load_word2vec_format(\"../models/model_big_one.vec\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(word):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 in [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'p' in ['y', 'p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
